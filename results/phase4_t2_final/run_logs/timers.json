{
    "name": "root",
    "gauges": {
        "NPCAgent.Policy.Entropy.mean": {
            "value": 1.4010826349258423,
            "min": 1.398932695388794,
            "max": 1.4974385499954224,
            "count": 100
        },
        "NPCAgent.Policy.Entropy.sum": {
            "value": 69996.6875,
            "min": 69925.53125,
            "max": 74850.9609375,
            "count": 100
        },
        "NPCAgent.Environment.EpisodeLength.mean": {
            "value": 160.96116504854368,
            "min": 98.07741935483871,
            "max": 381.7278911564626,
            "count": 100
        },
        "NPCAgent.Environment.EpisodeLength.sum": {
            "value": 49737.0,
            "min": 40446.0,
            "max": 57302.0,
            "count": 100
        },
        "NPCAgent.Step.mean": {
            "value": 4999957.0,
            "min": 49953.0,
            "max": 4999957.0,
            "count": 100
        },
        "NPCAgent.Step.sum": {
            "value": 4999957.0,
            "min": 49953.0,
            "max": 4999957.0,
            "count": 100
        },
        "NPCAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.2468673586845398,
            "min": -0.1961805671453476,
            "max": 0.3976380527019501,
            "count": 100
        },
        "NPCAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 230.08038330078125,
            "min": -176.75869750976562,
            "max": 399.2286071777344,
            "count": 100
        },
        "NPCAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 0.1360337734222412,
            "min": 0.06816311180591583,
            "max": 0.48191359639167786,
            "count": 100
        },
        "NPCAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 126.78347778320312,
            "min": 59.16558074951172,
            "max": 434.20416259765625,
            "count": 100
        },
        "NPCAgent.Environment.CumulativeReward.mean": {
            "value": 0.6721262180828113,
            "min": 0.06615387489205425,
            "max": 0.776540795196534,
            "count": 100
        },
        "NPCAgent.Environment.CumulativeReward.sum": {
            "value": 207.68700138758868,
            "min": 13.627698227763176,
            "max": 340.9692008094862,
            "count": 100
        },
        "NPCAgent.Policy.ExtrinsicReward.mean": {
            "value": 0.6721262180828113,
            "min": 0.06615387489205425,
            "max": 0.776540795196534,
            "count": 100
        },
        "NPCAgent.Policy.ExtrinsicReward.sum": {
            "value": 207.68700138758868,
            "min": 13.627698227763176,
            "max": 340.9692008094862,
            "count": 100
        },
        "NPCAgent.Policy.CuriosityReward.mean": {
            "value": 0.2253658622016333,
            "min": 0.08810428942163546,
            "max": 0.8100856749778297,
            "count": 100
        },
        "NPCAgent.Policy.CuriosityReward.sum": {
            "value": 69.63805142030469,
            "min": 27.167258606525138,
            "max": 166.87764904543292,
            "count": 100
        },
        "NPCAgent.Losses.PolicyLoss.mean": {
            "value": 0.024124311102132198,
            "min": 0.02010373080915694,
            "max": 0.027312462894866864,
            "count": 100
        },
        "NPCAgent.Losses.PolicyLoss.sum": {
            "value": 0.12062155551066099,
            "min": 0.08378109840690134,
            "max": 0.1365623144743343,
            "count": 100
        },
        "NPCAgent.Losses.ValueLoss.mean": {
            "value": 0.007159065124578773,
            "min": 0.004173329506690303,
            "max": 0.01827745558694005,
            "count": 100
        },
        "NPCAgent.Losses.ValueLoss.sum": {
            "value": 0.035795325622893864,
            "min": 0.0183775960894612,
            "max": 0.09138727793470025,
            "count": 100
        },
        "NPCAgent.Policy.LearningRate.mean": {
            "value": 1.6456834514720042e-06,
            "min": 1.6456834514720042e-06,
            "max": 0.000298460145513285,
            "count": 100
        },
        "NPCAgent.Policy.LearningRate.sum": {
            "value": 8.228417257360021e-06,
            "min": 8.228417257360021e-06,
            "max": 0.0014784286271904599,
            "count": 100
        },
        "NPCAgent.Policy.Epsilon.mean": {
            "value": 0.100548528,
            "min": 0.100548528,
            "max": 0.19948671500000006,
            "count": 100
        },
        "NPCAgent.Policy.Epsilon.sum": {
            "value": 0.50274264,
            "min": 0.41001056,
            "max": 0.99280954,
            "count": 100
        },
        "NPCAgent.Policy.Beta.mean": {
            "value": 3.737154720000008e-05,
            "min": 3.737154720000008e-05,
            "max": 0.0049743870785,
            "count": 100
        },
        "NPCAgent.Policy.Beta.sum": {
            "value": 0.00018685773600000038,
            "min": 0.00018685773600000038,
            "max": 0.024641196046000003,
            "count": 100
        },
        "NPCAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.12264081940054894,
            "min": 0.05045467267433802,
            "max": 1.9130961924791337,
            "count": 100
        },
        "NPCAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 0.6132040970027447,
            "min": 0.2018186906973521,
            "max": 7.652384769916535,
            "count": 100
        },
        "NPCAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 1.2232791010538737,
            "min": 0.9648364762465158,
            "max": 2.1641286551952366,
            "count": 100
        },
        "NPCAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 6.116395505269368,
            "min": 4.46092698375384,
            "max": 10.719053347905477,
            "count": 100
        },
        "NPCAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "NPCAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "PlayerAgent.Policy.Entropy.mean": {
            "value": 1.666700839996338,
            "min": 1.599804162979126,
            "max": 2.1075310707092285,
            "count": 100
        },
        "PlayerAgent.Policy.Entropy.sum": {
            "value": 83356.7109375,
            "min": 79910.21875,
            "max": 105563.1953125,
            "count": 100
        },
        "PlayerAgent.Environment.EpisodeLength.mean": {
            "value": 175.00335570469798,
            "min": 105.07221006564552,
            "max": 410.14503816793894,
            "count": 100
        },
        "PlayerAgent.Environment.EpisodeLength.sum": {
            "value": 52151.0,
            "min": 38055.0,
            "max": 58551.0,
            "count": 100
        },
        "PlayerAgent.Step.mean": {
            "value": 4999957.0,
            "min": 49953.0,
            "max": 4999957.0,
            "count": 100
        },
        "PlayerAgent.Step.sum": {
            "value": 4999957.0,
            "min": 49953.0,
            "max": 4999957.0,
            "count": 100
        },
        "PlayerAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.3259773552417755,
            "min": -0.7904247045516968,
            "max": -0.1957666575908661,
            "count": 100
        },
        "PlayerAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -301.20306396484375,
            "min": -709.010986328125,
            "max": -165.42282104492188,
            "count": 100
        },
        "PlayerAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 0.00417978223413229,
            "min": -0.3576267659664154,
            "max": 0.0720042735338211,
            "count": 100
        },
        "PlayerAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 3.86211895942688,
            "min": -320.79119873046875,
            "max": 71.57225036621094,
            "count": 100
        },
        "PlayerAgent.Environment.CumulativeReward.mean": {
            "value": -0.8871520182067816,
            "min": -1.0121871028215654,
            "max": -0.5816664494662251,
            "count": 100
        },
        "PlayerAgent.Environment.CumulativeReward.sum": {
            "value": -264.3713014256209,
            "min": -388.79470580164343,
            "max": -109.52290152944624,
            "count": 100
        },
        "PlayerAgent.Policy.ExtrinsicReward.mean": {
            "value": -0.8871520182067816,
            "min": -1.0121871028215654,
            "max": -0.5816664494662251,
            "count": 100
        },
        "PlayerAgent.Policy.ExtrinsicReward.sum": {
            "value": -264.3713014256209,
            "min": -388.79470580164343,
            "max": -109.52290152944624,
            "count": 100
        },
        "PlayerAgent.Policy.CuriosityReward.mean": {
            "value": 0.007555515859551469,
            "min": 0.00697493623363211,
            "max": 0.846932453701078,
            "count": 100
        },
        "PlayerAgent.Policy.CuriosityReward.sum": {
            "value": 2.2515437261463376,
            "min": 1.8985939942867844,
            "max": 170.23342319391668,
            "count": 100
        },
        "PlayerAgent.Losses.PolicyLoss.mean": {
            "value": 0.02367272170338159,
            "min": 0.01998784300095091,
            "max": 0.026806255788930377,
            "count": 100
        },
        "PlayerAgent.Losses.PolicyLoss.sum": {
            "value": 0.11836360851690794,
            "min": 0.08290632466863221,
            "max": 0.1340312789446519,
            "count": 100
        },
        "PlayerAgent.Losses.ValueLoss.mean": {
            "value": 0.006723985847396155,
            "min": 0.003718027257612751,
            "max": 0.016174813012282054,
            "count": 100
        },
        "PlayerAgent.Losses.ValueLoss.sum": {
            "value": 0.033619929236980775,
            "min": 0.014872109030451004,
            "max": 0.08087406506141027,
            "count": 100
        },
        "PlayerAgent.Policy.LearningRate.mean": {
            "value": 1.624815458427997e-06,
            "min": 1.624815458427997e-06,
            "max": 0.000298460145513285,
            "count": 100
        },
        "PlayerAgent.Policy.LearningRate.sum": {
            "value": 8.124077292139984e-06,
            "min": 8.124077292139984e-06,
            "max": 0.0014784286271904599,
            "count": 100
        },
        "PlayerAgent.Policy.Epsilon.mean": {
            "value": 0.10054157200000002,
            "min": 0.10054157200000002,
            "max": 0.19948671500000006,
            "count": 100
        },
        "PlayerAgent.Policy.Epsilon.sum": {
            "value": 0.5027078600000001,
            "min": 0.4099766199999999,
            "max": 0.99280954,
            "count": 100
        },
        "PlayerAgent.Policy.Beta.mean": {
            "value": 3.702444279999995e-05,
            "min": 3.702444279999995e-05,
            "max": 0.0049743870785,
            "count": 100
        },
        "PlayerAgent.Policy.Beta.sum": {
            "value": 0.00018512221399999976,
            "min": 0.00018512221399999976,
            "max": 0.024641196046000003,
            "count": 100
        },
        "PlayerAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.004058644178633888,
            "min": 0.003683800272798787,
            "max": 2.676723604525129,
            "count": 100
        },
        "PlayerAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 0.020293220893169442,
            "min": 0.01784570350622137,
            "max": 10.706894418100516,
            "count": 100
        },
        "PlayerAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 1.5615450231234234,
            "min": 1.2623803257942199,
            "max": 1.6980957637230554,
            "count": 100
        },
        "PlayerAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 7.807725115617116,
            "min": 5.2618027329444885,
            "max": 8.456206222375235,
            "count": 100
        },
        "PlayerAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "PlayerAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1639311586",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Unity\\IA\\ML-Agents\\MLAgents-ShootAndDodge-IA\\venv\\Scripts\\mlagents-learn configs/trainer_new_config.yaml --force --run-id=phase4_t2",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.0+cu110",
        "numpy_version": "1.21.4",
        "end_time_seconds": "1639328658"
    },
    "total": 17072.2893021,
    "count": 1,
    "self": 0.051976200000353856,
    "children": {
        "run_training.setup": {
            "total": 0.16178849999999922,
            "count": 1,
            "self": 0.16178849999999922
        },
        "TrainerController.start_learning": {
            "total": 17072.0755374,
            "count": 1,
            "self": 19.387803600431653,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.238887600000002,
                    "count": 1,
                    "self": 11.238887600000002
                },
                "TrainerController.advance": {
                    "total": 17041.243982299566,
                    "count": 579504,
                    "self": 25.311185199239844,
                    "children": {
                        "env_step": {
                            "total": 10311.324688100269,
                            "count": 579504,
                            "self": 8270.294655599882,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 2028.6820376000328,
                                    "count": 579504,
                                    "self": 89.28150849949543,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1939.4005291005374,
                                            "count": 1111184,
                                            "self": 421.6486781003646,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 1517.7518510001728,
                                                    "count": 1111184,
                                                    "self": 1517.7518510001728
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 12.347994900352699,
                                    "count": 579504,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 17029.839078699908,
                                            "count": 579504,
                                            "is_parallel": true,
                                            "self": 10267.254387000406,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.005145099999998237,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0018784999999983398,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0032665999999998974,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0032665999999998974
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 6762.579546599502,
                                                    "count": 579504,
                                                    "is_parallel": true,
                                                    "self": 245.21242509801868,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 332.65581170011023,
                                                            "count": 579504,
                                                            "is_parallel": true,
                                                            "self": 332.65581170011023
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 5308.460480901131,
                                                            "count": 579504,
                                                            "is_parallel": true,
                                                            "self": 5308.460480901131
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 876.250828900242,
                                                            "count": 1159008,
                                                            "is_parallel": true,
                                                            "self": 403.28818140293447,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 472.96264749730756,
                                                                    "count": 4636032,
                                                                    "is_parallel": true,
                                                                    "self": 472.96264749730756
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 6704.608109000057,
                            "count": 1159008,
                            "self": 50.144453598652035,
                            "children": {
                                "process_trajectory": {
                                    "total": 1624.4048760014318,
                                    "count": 1159008,
                                    "self": 1622.211024201433,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 2.1938517999988107,
                                            "count": 20,
                                            "self": 2.1938517999988107
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 5030.058779399973,
                                    "count": 972,
                                    "self": 2206.684900099901,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 2823.373879300072,
                                            "count": 29160,
                                            "self": 2823.373879300072
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 5.000001692678779e-06,
                    "count": 1,
                    "self": 5.000001692678779e-06
                },
                "TrainerController._save_models": {
                    "total": 0.20485890000054496,
                    "count": 1,
                    "self": 0.02930960000230698,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.17554929999823798,
                            "count": 2,
                            "self": 0.17554929999823798
                        }
                    }
                }
            }
        }
    }
}